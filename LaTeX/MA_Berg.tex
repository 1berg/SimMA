 \documentclass[paper=a4, DIV=calc, BCOR=12mm, twoside=on, onecolumn=on, open = right, titlepage =on, parskip =half-, headsepline = on, footsepline = off, chapterprefix = off, appendixprefix = on, fontsize = 12pt, numbers = noenddot, abstract = on]{scrbook}
\input{preamble}
\setcounter{tocdepth}{1}

\usepackage{blindtext}
\usepackage{todonotes}

\usepackage{setspace}


\begin{document}
\newpage
\thispagestyle{plain}

\pagenumbering{Roman}


\include{titlepage}
\KOMAoptions{DIV=calc, BCOR=12mm, twoside=on}
\thispagestyle{empty}
\newpage
\thispagestyle{empty}

\addchap*{Abstract}
\onehalfspacing
Simulation environments are a long established part of scientific research in robotics. Before risking fragile equipment to be damaged in real life testing, a simulation based on the specific prerequisites will help approximating the expected results.

In this master thesis a Java-based simulation environment for \textsc{LEGO Mindstorms} NXT robots is developed. The environment is developed for schools and has the ability to make the basic tasks of a NXT robot visible. The requirements and restraints of such an environment will be exemplified and completed by the subsumption of the topic in the academic curriculum. Furthermore, an elaborated description of the software architecture will be presented. In conclusion, the implementation results and further demands on the simulation environment, which have benn developed through interviewing computer science teachers, will be described.

\addchap*{Zusammenfassung}
\onehalfspacing
Simulationsumgebungen sind im Bereich der wissenschaftlichen Arbeit mit Robotern bereits fest etabliert. Bevor Testungen unter Realbedingungen stattfinden, in der fragiles Equipment beschädigt werden könnte, werden diese mithilfe von Simulationen so gut wie möglich approximiert.

In dieser Masterarbeit wird eine Java-basierte Simualtionsumgebung für \textsc{LEGO Mindstorms} NXT Roboter entwickelt. Diese ist für den Einsatz in Schulen konzipiert und kann die grundlegenden Aufgaben eines NXT Roboters simuliert darstellen. Es werden Anforderungen und Einschränkungen einer solchen Umgebung erläutert und es erfolgt die curriculare Einordnung des Themas in den Bildungskontext Schule. Des Weiteren ist eine ausführliche Beschreibung der Softwarearchitektur in dieser Arbeit enthalten. Abschließend werden die Ergebnisse der Implementation, sowie weitere Anforderungen dieser Simulationsumgebung, die sich aus der Befragung von Informatik-Lehrkräften ergaben, zusammengefasst dargestellt.

\singlespacing
\newpage
\listoffigures
\newpage
\tableofcontents
\thispagestyle{empty}
\cleardoublepage
\newpage
\pagenumbering{arabic}
\par \singlespacing
\chapter{Einleitung}
\label{sec:einleitung}
\onehalfspacing
"`Informatik in der Schule"' ist ein bildungspolitisch umfassend diskutiertes Thema der letzten Jahre. Eine zentrale Rolle nimmt dabei die Frage ein, ob es sinnvoll sei, ein Unterrichtsfach "`Programmieren"' ab der Grundschule einzuführen, oder ob es reicht, dass die Schülerinnen und Schüler dazu ausgebildet werden einen Computer bedienen zu können. Dabei stehen sich die Grundgedanken der beiden Extreme, nämlich die Schülerinnen und Schüler als kompetente Computer-Nutzer mit einem Verständnis der logischen Strukturen hinter der Benutzeroberfläche auf der einen und das Heranziehen einer Generation von Schülerinnen und Schülern, die auf die Verwendung der gängigen Office-Anwendungen geschult wurde, auf der anderen Seite, gegenüber.

In der gymnasialen Oberstufe ist das Erlernen einer Programmiersprache derzeit schon vorgesehen. Doch auch ab der fünften Klasse kann bereits mit dem Erlernen von objektorientierten Programmierparadigmen begonnen werden. Eine wertvolle Ergänzung des klassischen Unterrichts hat sich in den letzten Jahren aus der Entwicklung der Ganztagsschulprogramme herauskristallisiert -- im Nachmittagsbereich wurden nun neben sportlichen und musisch-künstlerischen Angeboten sowie klassischer Nachhilfe Roboter-Arbeitsgemeinschaften gegründet, in denen Schülerinnen und Schüler an die Technik von verschiedensten programmierbaren Robotern herangeführt werden.

Auf spielerische Art und Weise sollen Schülerinnen und Schüler (im Folgenden SuS abgekürzt) mit einfachen Konstrukten der objektorientierten Programmierung umzugehen lernen. Der Grundgedanke hinter diesem Konzept reicht bis in die Siebzigerjahre des letzten Jahrhunderts: Der Mathematiker, Informatiker und Psychologe Seymour Papert hat schon damals herausgefunden, dass das Ziel, Kinder zum Programmieren zu bringen, mithilfe einer spielerischen Herangehensweise erreicht werden könnte. Hierdurch entstand das bis heute bekannte Konzept der \emph{Turtle} (vgl. \cite[S.365]{nievergelt:99}).

Heutzutage wird der spielerische Aspekt beim Programmieren im Zusammenhang mit \textsc{LEGO Mindstorms} Robotern zum einen mit Drag-and-Drop Softwareangeboten wie das standardmäßig mit ausgelieferte \emph{NXT Mindstorms Tool} (s.  \textbf{\ref{sec:LMNXT}}), oder auch \emph{Enchanting} (s. \textbf{\ref{sec:enchanting}}) realisiert. Zum anderen bietet sich ab der Mittelstufe (Klasse 7 -- 10) die Arbeit mit BlueJ zur Erstellung erster selbstgeschriebener Programme an. Hierzu kann eine BlueJ Extension genutzt werden, die mit der Java Virtual Machine \emph{leJOS NXJ} für NXT Roboter (s. \textbf{\ref{sec:lejos}}) arbeitet.

Immer wieder stoßen Lehrkräfte in den Schulen auf Hardwareprobleme jeglicher Art, wie zum Beispiel eine unzureichende Anzahl an Robotern im Unterricht oder auch fehlende Firmwareupdates oder defekte Sensoren.

Auch das Zusammen- und wieder Auseinanderbauen der Roboter ist ein Aufwand, der für den alltäglichen Unterricht nicht geeignet ist. Um kleine Aufgaben -- wie zum Beispiel das Fahren einer Kurve oder das Anhalten auf einem bestimmten Punkt -- mit Java zu lösen, muss bisher immer erst der Roboter gestartet, der Code in BlueJ verfasst und auf den Roboter übertragen werden. Schließlich muss der Roboter noch zu einem geeigeneten Parcours gebracht werden, um die Lösung testen zu können.

Um diese Probleme zu umgehen und den Einstieg in die objektorientierte Programmierung mit \textsc{LEGO Mindstorms} Robotern zu optimieren, soll im Rahmen dieser Masterarbeit der Protoyp einer Simulationsumgebung für die Arbeit mit \textsc{LEGO Mindstorms} NXT Roboter entwickelt werden. Im Zusammenhang mit dieser Arbeit wurden die beiden folgenden Forschungsfragen herausgearbeitet, die einen gedanklichen Leitfaden und die Basis für die Verknüpfung von theoretischen Überlegungen und Implementation darstellen:
\begin{quote}
Welche Anforderungen werden an eine solche Simulationsumgebung gestellt -- aus Schülerperspektive, aus Lehrerperspektive, aus Entwicklerperspektive?

Welche Integrationsmöglichkeit bietet BlueJ und wie kann diese sinnvoll genutzt werden?
\end{quote}

Es wird nun zunächst die Ausgangssituation im schulischen Kontext beschrieben, sowie ein Einblick in die Arbeit mit \textsc{LEGO Mindstorms} Robotern im Unterricht gegeben. Anschließend werden die bisher verfügbaren Softwarelösungen zur Programmierung von \textsc{LEGO Mindstorms} NXT Robotern vorgestellt, insbesondere die bisherigen Versuche, Simulationsumgebungen zu realisieren.

Vor der Beschreibung der entwickelten Software werden zudem die an die Neuplemenation gestellten Anforderungen vorgestellt, die dann im letzten Kapitel -- nach der Vorstellung der Software -- mit der tatsächlichen Funktionalität der entwickelten prototypischen Simulationsumgebung verwoben werden.

Abschließend werden weitere, von aktiven Lehrkräften gestellte Anforderungen an die Simulationsumgebung, sowie Verbesserungen und Erweiterungsmöglichkeiten, die sich im Laufe der Implementation entwickelt haben, erläutert.
\newpage
\par\singlespacing
\chapter{Ausgangssituation}

\par\singlespacing
\section{Das LEGO Mindstorms NXT System}
\onehalfspacing
\subsection{Geschichte der \textsc{LEGO} Robotik}
Die ersten computergesteuerten \textsc{LEGO} Produkte wurden bereits 1986 veröffentlicht. In einer Zusammenarbeit von \textsc{LEGO} Education und dem Massachussettes Institute of Technology (MIT) wurde \textsc{LEGO TC LOGO} entwickelt. Dies war eine spezielle Abwandlung der Programmiersprache LOGO, mit der zusammengesetzte \textsc{LEGO}-Modelle gesteuert werden konnten (vgl. \cite{rolling:14}).

Die Entwicklung eines programmierbaren \textsc{LEGO}-Steins begann 1988 und erreichte ihren Höhepunkt mit der Vorstellung des ersten Mindstorms Systems im Januar 1998, bei der der \textsc{LEGO Mindstorms RCX Intelligent Brick} -- ein Microcomputer und somit das Kernstück des RCX-Systems -- und das \emph{Robotics Invention System} im Museum of Modern Art in London vorgestellt wurden.

Bereits zwei Monate nach Verkaufsstart wurde die FIRST LEGO League (FLL) gegründet -- eine Zusammenarbeit zwischen \textsc{LEGO} und FIRST (For Inspiration and Recognition of Science and Technology), die den Grundstein für die heute noch bestehende Wettbewerbsliga legte (vgl. \cite{rolling:14}).

Die Vorstellung und der Verkaufsstart der Nachfolge-Roboter des RCX-Systems, den \textsc{LEGO Mindstorms} NXT Robotern, fand im August 2006 statt. Diese damals neu entwickelten Roboter sind dank eines Updates in 2009 fast zehn Jahre später noch in den Schulen und Universitäten zu finden. Im April 2005 fand die erste FLL Weltmeisterschaft in Atlanta, Georgia, statt und bis heute bieten die Weltmeisterschaften einen Anlaufpunkt für Jugendliche auf der ganzen Welt, die ihr Können und ihre Roboter auf die Probe stellen wollen (s. \cite{lego}).

\par \singlespacing
\subsection{Hardware}
\onehalfspacing
Zentraler Bestandteil der \textsc{LEGO Mindstorms} NXT Roboter ist der sogenannte NXT-Stein. Dieser besteht aus einem 32 Bit ARM-Prozessor und einem 8 Bit Co-Prozessor. Der Hauptprozessor ist für die Ausführung des Hauptprogramms zuständig, während sich der Co-Prozessor um die Auswertung etwaiger Sensordaten kümmert, die dann an den Hauptprozessor weitergeleitet werden. Für die Kommunikation mit dem NXT-Stein stehen zwei Komponenten zur Verfügung. Zum einen eine Kabelverbindung mit einer USB 2.0 Schnittstelle, zum anderen bietet der NXT-Stein -- wie schon der Vorgänger RCX -- die Möglichkeit einer Kommunikation über Bluetooth an. Das Softwaremenü wird auf dem 100 x 64 Pixel großen LCD-Bildschirm angezeigt und kann über die vier Kontrolltasten auf der Oberseite des NXT-Steins bedient werden. Für eine ausreichende Stromversorgung wird entweder mittels Batterien oder eines Akkus gesorgt (vgl. \cite[S.42]{berns:10}).

Der NXT-Stein verfügt standardmäßig über drei Motoranschlüsse (\emph{Motorports}) und vier Sensoranschlüsse (\emph{Sensorports}), die jeweils mit Buchstaben (\emph{A, B, C} bei den Motoren) bzw. Nummern (\emph{1, 2, 3, 4} als Sensoranschlüsse) bezeichnet sind (vgl.  \cite[S.43]{berns:10}). An zwei der drei verfügbaren Motorports ist jeweils ein Elektromotor angeschlossen. In diese Motoren sind Rotationssensoren und Regler eingebaut, die dafür sorgen, dass sowohl die Drehgeschwindigkeit als auch die Umdrehungszahl mithilfe des Programmcodes kontrolliert werden kann (vgl. \cite[S.45--47]{berns:10}).

Für die NXT Roboter sind eine Vielzahl von Sensoren verfügbar, damit die SuS ihren Roboter sein Umfeld erkunden lassen können. Eine umfassende Übersicht der einzelnen Sensoren und deren spezifischen Funktionsweisen geben \textsc{Berns} und \textsc{Schmidt} (s. \cite[Kapitel 4.2]{berns:10}). 

\par \singlespacing
 \section{Die Arbeit mit LEGO-Robotern im Unterricht}
\onehalfspacing
Die Robotik als Teilgebiet der Informatik in der Schule gewinnt zunehmend an Bedeutung. Nicht nur die Programmierung steht im Vordergrund, sondern auch die Kompetenz, Probleme unter bestimmten Aufgabenstellungen zu lösen. \textsc{Berns} und \textsc{Schmidt}, die Verfasser eines der Kernwerke für den Unterricht mit dem \textsc{LEGO Mindstorms} System, schreiben, dass bei der Arbeit mit Robotern im Unterricht "`durch eine konkrete Aufgabenstellung, das problemspezifische Konstruieren und Programmieren eines Roboters sowie durch das letztendliche Testen der gesamte Ablauf eines Problemlösungsprozesses kennen gelernt [wird]"' \cite[S.2]{berns:10}.

In diesem Zusammenhang können auch, wie von \textsc{Wagner} ausführlich begründet, die Kooperationsfähigkeiten der SuS im besonderen Maße gefördert werden. Gründe hierfür bestehen unter anderem in der Vielzahl der Möglichkeiten, ein Problem mit Robotern zu lösen, die alle unterschiedlich gut geeignet sind, und durch welche die SuS zur Kommunikation und dem Verständlichmachen ihrer Ideen im Team angeregt werden. Hierbei ist das Augenmerk auch auf die Kontrollinstanz zu legen -- nimmt sonst die Lehrkraft diese Rolle für sich ein, so ist der Roboter bei dieser Art von Unterricht eine neutrale, unbestechliche und jederzeit verfügbare Möglichkeit, die geleistete Arbeit zu bewerten (vgl. \cite[S.6f.]{wagner:05}).

\textsc{Schreiber} fasst in seiner Examensarbeit den Einsatz von \textsc{LEGO Mindstorms} Robotern wie folgt zusammen
\begin{quote}
"`Als herausragende Qualität des Materials LEGO-Mindstorms erwies sich die damit erzielbare \textbf{Motivation}, welche ein hohes Maß an Selbsttätigkeit auch über einen längeren Zeitraum möglich machte. Diese Selbsttätigkeit ist die Form des idealen Lernen im Sinne der Handlungsorientierung und hat sich auch in dem durchgeführten Unterricht bewährt. [...] Die \textbf{Sozialform} der Partnerarbeit erwies sich als weit gehend produktiv, zum einen, weil inhaltlich miteinander beraten werden konnte und wurde [...], zum anderen, weil ein LEGO-Mindstorms-Roboter auch für zwei gleichzeitig tätige Personen genug Handlungsmöglichkeiten bietet"' \cite[S.47f.]{schreiber:04}.
\end{quote}

Ähnlich beschreibt es auch \textsc{Stolt} in seiner Ausarbeitung:
\begin{quote}
"`Ein großer Punkt, der für das Roboterlabor spricht, ist das starke Motivationspotential für die Teilnehmer sich mit Informatikthemenstellungen zu befassen. Die Entwicklung einer eigenen Lösung einer Aufgabe, mit anschliessendem Wettbewerb besitzt trotz – oder vielleicht gerade wegen – der möglichen Komplexität einen sehr großen Unterhaltungswert und stelle eine spannende Herausforderung dar. Pädagogisch ist das Roboterlabor durch seine teamorientierte Arbeitsweise und die Möglichkeit zum explorativen Lernen interessant. Didaktisch steht hier das Erlernen und Erfahren von Programmier- und Designmethoden im Vordergrund"' \cite[S.5f.]{stolt:01}.
\end{quote}

Grundsätzlich ist also zu sagen, dass der Einsatz von Robotern im Unterricht als sowohl didaktisch sinnvoll gesehen wird, als auch die Motivation der SuS in diesem Zusammenhang einen starken Einfluss auf den Lernerfolg und die Selbstständigkeit haben kann. 

Es erfolgt nun zunächst die curriculare Einordnung des Themas Roboter im Unterricht in die Bildungspläne aus Hamburg. Danach werden verschiedene Arbeitsmethoden im Zusammenhang mit dieser Art von Unterricht vorgestellt.
\clearpage

\section{Curriculare Einordnung}
Die fachlichen Inhalte, die mithilfe des Einsatzes von Robotern im Unterricht vermittelt werden können, sind sowohl im Bildungsplan der Sekundarstufe I für das Gymnasium (Klasse 7 -- 10) und die Stadtteilschule (Klasse 7 -- 11), als auch im Bildungs- bzw. Rahmenplan für die Gymnasiale Oberstufe, der Sekundarstufe II, verankert. Der folgende Abschnitt gibt eine Übersicht über die verschiedenen Module im Zusammenhang mit den Unterscheidungen zur Schulform und Klassenstufe.

Grundsätzlich ist vorab zu erwähnen, dass die im Folgenden vorgestellten Bildungspläne ausschließlich für die Freie und Hansestadt Hamburg gelten. Des Weiteren existiert jeweils ein Bildungsplan für die Sekundarstufe I der weiterführenden Schulen (Stadtteilschule und Gymnasium) sowie ein einheitlicher Bildungsplan für die Gymnasiale Oberstufe, wobei der elfte Jahrgang sowohl im Bildungsplan der Stadtteilschule, als auch im Bildungsplan für die Vorstufe der Gymnasialen Oberstufe vertreten ist. 
%\vspace*{-2ex}
\subsection{Gymnasium Sekundarstufe I (7 -- 10) Informatik Wahlpflichtfach}
Der Einsatz von Robotern kann auf die Module 2 und 3 des Bildungsplanes für die Sekundarstufe I des Gymnasiums bezogen werden und stellt einen möglichen Inhalt zu dem Erwerb und der Förderung der festgelegten Kompetenzen dar. Im Bildungsplan werden diese durch die folgenden Module untergliedert:
\clearpage

 \begin{quote}
Modul 2
\begin{itemize}
\item Abläufe analysieren und umgangssprachlich beschreiben, Algorithmen formalisieren und mit einer formalen Sprache implementieren
\item Umgang mit einer einfachen Entwicklungsumgebung
\item Testen, Ergebnisse interpretieren und bewerten
\item Grundlagen der prozeduralen Programmierung: Sequenz, Alternative, Wiederholung, Prozedur bzw. Funktion
\end{itemize}

Modul 3 -- Kontext Daten und Prozesse
\begin{itemize}
\item Grundlagen der prozeduralen Programmierung
\item Abläufe formalisieren
\item Algorithmen mit einer formalen Sprache implementieren
\item Testen, Ergebnisse interpretieren und bewerten \hfill \cite{gymsek1:11} 
\end{itemize}
 \end{quote}


%\vspace*{-2ex}
\subsection{STS Jahrgangsstufen 7 --11 Informatik Wahlpflichtfach}
Ähnlich ist es im Bildungsplan für die Stadtteilschulen, welcher -- anders als der eben aufgeführte Bildungsplan der gymnasialen Sekundarstufe I -- auch die 11. Klasse umfasst. Hierbei werden zudem innerhalb der Module verbindliche Inhalte formuliert.

So sind im Modul 2 die Inhalte \emph{Algorithmen} und \emph{prozedurale Programmierung: Sequenz, Alternative, Wiederholung, Funktion} zu finden, die, wie der Bildungsplan vorschlägt, in das Unterrichtsvorhaben \emph{"Wir lassen Roboter arbeiten"} integriert werden können (vgl. \cite{stsmittel:14}). An dieser Stelle findet demnach ein klarer Bezug zum Einsatz von Robotern im Unterricht statt.

Im Modul 3 sollen im zweiten Halbjahr die folgenden verbindlichen Inhalte unterrichtet werden:
\begin{quote}
\begin{itemize}
\item Grundlagen der prozeduralen Programmierung
\item Abläufe formalisieren
\item Algorithmen mit einer formalen Sprache implementieren
\item Testen, Ergebnisse interpretieren und bewerten \hfill \cite{stsmittel:14}
\end{itemize}
\end{quote}


\vspace*{-1ex}
\subsection{Gymnasiale Oberstufe -- Vorstufe}

In der Vorstufe sollen sich die SuS mit den Inhalten des Moduls \emph{Daten und Prozesse} beschäftigen. Diese beinhalten das Analysieren und umgangssprachliche Bescheiben von Abläufen, das Strukturieren von Daten sowie die Verwendung von Variablen und Parametern, das Formalisieren von Abläufen, die Grundlagen der prozeduralen Programmierung, die Implementation von Algorithmen mit einer formalen Sprache, das Testen, Interpretieren und Bewerten von Ergebnissen (vgl. \cite{oberstufe:09}). 
\vspace*{-1ex}
\subsection{Gymnasiale Oberstufe -- Studienstufe}
Die Studienstufe der gymnasialen Oberstufe bezieht sich auf die letzten beiden Schuljahre sowohl des Gymnasiums als auch der Stadtteilschule.

In der Studienstufe ist im Bildungsplan unter anderem der verbindliche Inhalt \emph{Objektorientierte Modellierung} aufgeführt. Dieser umfasst die folgenden Punkte.
\begin{quote}
\begin{itemize}
\item Idee des OO-Konzepts mit Objekten und ihrer Kommunikation, Vererbung und Nutzerbeziehung
\item Erarbeitung der Sprachelemente der verwendeten objektorientierten Programmiersprache, Berücksichtigung von Programmierkonventionen, Nutzen von Bausteinen/Libraries
\item Nutzung einer IDE mit UML-Diagrammen und Quellcode zur schrittweisen Implementierung eines Informatiksystems. \hfill \cite{oberstufe:09}
\end{itemize}
\end{quote}


Insgesamt ist festzustellen, dass die Arbeit mit Robotern im Informatikunterricht keine Beeinträchtigungen durch den Bildungsplan erfährt. Eher kann aufgrund der Bildungspläne der universelle Einsatz von Robotern als Hilfestellung für die SuS dienen, denn die Lehrkräfte können anhand von Praxisbeispielen leicht erkennbare Verknüpfungen zwischen den einzelnen Module, Themen und Anforderungsbereichen aufzeigen. Somit können in der 7. Klasse gelernte Inhalte durch Erinnern des Kontexts, in dem diese erarbeitet wurden, später leichter aufgegriffen werden.


\subsection{Einsatz von Robotern als Hilfsmittel im Unterricht}
Da laut Bildungsplan die projektorientierte Arbeit in Informatik in der Studienstufe einen bedeutenden Stellenwert hat, bietet es sich an, eine Projektarbeit zum Thema \emph{Einsatz von Robotern} mit Bezug auf verschiedene Ligen (schulisch und universitär) zu gestalten, bei der als Produkt eine bestimmte Aufgabe mit den Robotern erledigt werden soll.  Diese projektorientierte Arbeit hat den Vorteil, dass sie an einen realen Kontext geknüpft oder in ihn eingebettet werden kann. Wie \textsc{Hubwieser} in seinem Werk \emph{Didaktik der Informatik} verdeutlicht, kann dies einen positiven Einfluss auf die innere Einstellung der SuS gegenüber diesem teilweise recht anspruchsvollen Thema haben:
\begin{quote}
"`Nach den Erfahrungen mit der Umsetzung abstrakter Konzepte [...] im Mathematikunterricht des Gymnasiums scheint eine Vermittlung der naturgemäß abstrakten informatischen Lerninhalte nur dann erfolgversprechend, wenn durch konkrete, anschauliche Problemstellungen eine erhöhte Aufnahmebereitschaft der Schüler geschaffen wird "' \cite[S.68]{hubwieser:07}.
\end{quote}

Die einfachste Methode, um SuS an die problemorientierte Arbeitsweise im Rahmen der Programmierung mit Robotern heranzuführen ist der Einsatz von Fallbeispielen. Hierbei handelt es sich um aus der Realwelt gegriffene Umgebungen, die in unserem Fall mithilfe des Roboters erkundet werden sollen. Ein klassisches Fallbeispiel für den Einstieg wäre die Situation, dass der Roboter vor einem Hindernis steht, um das er herumfahren soll. Hierbei kann man den SuS vorgeben, dass sie z.B. im Viereck um das Hindernis herum navigieren sollen.

Ein weitaus komplexeres Beispiel bietet sich im Zusammenhang mit der RoboCup Wettbewerbsliga \emph{Rescue} an, in der ein in einem Labyrinth verstecktes Opfer gerettet werden soll. Hierbei würden sich nun die SuS damit beschäftigen, wie sie durch das Labyrinth navigieren, wie sie Hindernissen ausweichen, und welche bautechnischen Spezifikationen ihr Roboter haben muss, um das Opfer an einen sicheren Ort zu transportieren.

Der gemeinsame Konsens aller dargestellten Möglichkeiten des Robotereinsatzes im Unterricht ist der ihnen zugrunde liegende lerntheoretische Ansatz des \emph{Konstruktivismus}. Im Rahmen projektorientierter Arbeit kann Wissen als Rohmaterial vorbereitet werden, so dass SuS dieses individuell und in Interaktion mit dem Lerngegenstand aufbauen. Bedeutend ist hierbei, dass die SuS ihrem spezifischen Vorwissen entsprechend handeln und somit eine persönlich individuelle Verknüpfung zu dem neu konstruierten Wissen herstellen.
Der Unterricht folgt als Resultat dieses Ansatzes einem Paradigma des Problemlösens, bei dem alls SuS individuell aktiv sind und und die Lehrkraft in der Rolle des Moderators oder Lernberaters zur Seite steht (vgl. \cite[S.219f.]{schwarzer:07}).

\chapter{Bisher verfügbare Softwarelösungen}
\label{sec:software bisher}
In diesem Kapitel wird eine Auswahl von verfügbaren und im Unterricht getesteten Softwarelösungen zur Programmierung der NXT Roboter, sowie einige bereits verfügbare Simulationsumgebungen vorgestellt. 


\section{LEGO Mindstorms NXT}
\label{sec:LMNXT}

Das \textsc{LEGO Mindstorms} NXT-Programm ist eine von der Firma \textsc{LEGO} zur Verfügung gestellte Programmieroberfläche für NXT Roboter.

\begin{figure}[htb]
\centering
\includegraphics[width= \textwidth]{images/Startbildschirm_NXT.png} 
\caption[Der Startbildschirm des \textsc{LEGO} NXT-Programms]{Der Startbildschirm des \textsc{LEGO} NXT-\-Pro\-gramms}
\label{fig:NXT Start}
\end{figure}
Die Abbildung \ref{fig:NXT Start} zeigt den Startbildschirm der Entwicklungsumgebung. Dieser stellt neben zwei Videoanleitungen als Hilfe für Anfänger auch das \emph{Robo Center} zur Verfügung, in dem verschiedene von \textsc{LEGO} vorgeschlagene Roboter-Modelle vorgestellt werden, die mithilfe des Bausatzes des NXT zusammengesetzt werden können.

Sobald eine neue oder bestehende Programmdatei geöffnet wird, können die SuS ihren Roboter programmieren. Hierbei helfen ihnen Blöcke, die unter anderem der Bewegung und Sensorik dienen und dabei einfache Steuerungsmechanismen sowie Elemente der Regelungstechnik zur Verfügung stellen. Zur Programmierung werden Bausteine aus der linken Leiste per Drag-and-Drop auf die karierte Oberfläche gezogen. Es können ineinander geschachtelte Schleifen erstellt werden sowie if-Abfragen mit zwei Fallunterscheidungen. Nahezu beliebig viele Bausteine lassen sich so miteinander kombinieren (Vlg. Abb.\ref{fig:Bsp NXT}).

Der Vorteil an dieser Entwicklungsumgebung besteht darin, dass sie von \textsc{LEGO} zur Verfügung gestellt wurde, und somit alle Funktionen von Haus aus mitbringt, die dem NXT-Baustein technisch zur Verfügung stehen. Zudem muss es keine Veränderungen an der Firmware des NXT-Bausteins geben, was eine Zeitersparnis bei der Vorarbeit der SuS mit sich bringt.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/Beispielprogramm_NXT.png} 
\caption{Fahren eines Roboters auf einer schwarzen Linie}
\label{fig:Bsp NXT}
\end{figure}


\section{Enchanting}
\label{sec:enchanting}
Enchanting ist eine an das Einsteigertool für Objektorientierte Programmierung \emph{Scratch} anknüpfende Entwicklungsumgebung. Wie das in \textbf{\ref{sec:LMNXT}} beschriebene Programm wird auch hier mithilfe von Drag-and-Drop gearbeitet. Da Enchanting keine von LEGO nativ unterstützte Entwicklungsumgebung für NXT Roboter ist, muss hier eine Änderung an der Firmware vorgenommen werden. Hierbei wird die ausgelieferte Standardfirmware mit leJOS (s. \textbf{\ref{sec:lejos}}) ersetzt. Dies sorgt dafür, dass der NXT nun auf die Programmierung mit Java reagiert.


\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/Enchanting_Start.png} 
\caption{Der Startbildschirm von Enchanting}
\label{fig:Enchanting Start}
\end{figure}


Wird Enchanting von den SuS geöffnet, erscheint zunächst der Startbildschirm wie in Abbildung \ref{fig:Enchanting Start}. Nun kann entweder ein neues Programm erstellt oder ein bestehendes geöffnet werden. Die verschiedenen Programmierelemente werden nach Kategorien in den oberen linken Ecke sortiert aufgeführt. Essentiell dabei sind die Kategorien \emph{Steuerung}, \emph{Fühlen}, \emph{Motoren} und \emph{Formeln}. Die SuS lernen beim Programmieren mit Enchanting, dass sie ihre Motoren und Sensoren zunächst über die verschiedenen Ports referenzieren müssen. Dies geschieht, indem man beispielsweise einen Motor-Block an einen Port setzt und ihm einen aussagekräftigen Namen gibt. Auf diese Weise kann nun -- anders als beim \textsc{LEGO Mindstorms} NXT-Programm -- bei Kontrollstrukturen mithilfe des Namens auf den Motor oder Sensor zugegriffen werden.

In Abbildung \ref{fig:Bsp Enchanting} ist ein simples Programm zum Fahren entlang einer schwarzen Linie mithilfe von zwei Lichtsensoren dargestellt. Hierbei ist zu erkennen, dass die Sensoren in den Abfrage-Blöcken mit \texttt{rechts} und \texttt{links}, die Motoren in den türkisfarbenen Elementen mit \texttt{NXT rechts 1} sowie \texttt{NXT links 2} bezeichnet sind. Es kann somit von den SuS direkt aufgezeigt werden, welcher Sensor angesprochen wird, und welcher Motor an welchem Port angeschlossen ist.


\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/Beispielprogramm_Enchanting.png} 
\caption{Beispiel eines Enchanting Programms}
\label{fig:Bsp Enchanting}
\end{figure}



\section{Schriftliche Programmierung von NXT Robotern}
\label{sec:bluejetc}
Neben den grafischen Entwicklungsumgebungen in \textbf{\ref{sec:LMNXT}} und \textbf{\ref{sec:enchanting}} stehen natürlich auch Werkzeuge zur schriftlichen Programmierung der NXT Roboter zur Verfügung. Nachfolgend wird eine der geläufigen Kombinationen aus Entwicklungsumgebung und virtueller Maschine für \textsc{LEGO Mindstorms} NXT vorgestellt. 
\vfill

\subsection{BlueJ}
\label{sec:bluej}
Die Java-Entwicklungsumgebung BlueJ wurde an der Monash University in Australien entwickelt. Das Ziel von BlueJ war von Beginn an klar definiert: Es sollte eine einfache Umgebung für den Einstieg in die objektorientierte Programmierung geschaffen werden (vgl. \cite[S.14]{barnes:03}).

Jedoch handelt es sich bei der Entwicklung objektorientierter Programme mit BlueJ keinesfalls um die Benutzung einer reduzierten Version von Java. BlueJ läuft wie andere Entwicklungsumgebungen auf dem aktuellen Java Development Kit (JDK) und auch als Compiler und virtuelle Maschine (JVM) wird Software der Firma Oracle (bis 2010 Sun Microsystems) verwendet (vgl. \cite[S.15]{barnes:03}).

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/firstprogram.png}
\caption{Die Benutzeroberfläche von BlueJ}
\label{fig:BlueJ UI}
\end{figure}

Nicht nur in den Universitäten wird BlueJ inzwischen als Werkzeug zur Einführung in die Programmiersprache Java und die objektorientierte Programmierung genutzt, auch im Schulkontext hat die intuitive Bedienung und übersichtliche Gestaltung Anklang gefunden, da BlueJ "`eine einfache Entwurfssicht für die Analyse gegebener Lösungen und für die Planung neuer Lösungen"' \cite[S.6]{ehmann:09} zur Verfügung stellt. Eine weitere Besonderheit besteht darin, dass -- im Gegensatz zu den meisten anderen Entwicklungsumgebungen -- in BlueJ "`schnell einige Objekte erzeugt und sofort untersucht werden"' \cite[S.6]{ehmann:09} können. Hierzu bietet BlueJ die \emph{Inspect-}Funktion an, die über das Kontextmenü eines erzeugten Objekts erreichbar ist und die Werte der Feldvariablen genau dieses Exemplars einer Klasse anzeigt.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/linienfinder_bluej.png} 
\caption{BlueJ-Beispiel zum Finden einer Linie}
\label{fig:Bsp BlueJ Linienfinder}
\end{figure}


\par \singlespacing
\subsection{leJOS}
\label{sec:lejos}
\onehalfspacing
leJOS ist eine kleine Java Virtual Machine und stellt alle Klassen der NXJ API zu Verfügung, mithilfe derer \textsc{Lego Mindstorms} NXT Roboter in Java programmiert werden können (vgl. \cite{lejos}).

In der Kombination mit BlueJ ergibt sich somit für die SuS eine besonders einfache Softwarelösung. Durch eine eigens für BlueJ und NXT Roboter geschriebene sogenannte \textit{Extension} (siehe hierzu \cite{bowes:12}) und den Import der NXJ API stehen den SuS nicht nur die Klassen zur Steuerung ihres Roboters zur Verfügung. Darüber hinaus besteht Möglichkeit, über eine Erweiterung des Kontextmenüs um spezielle Befehle, das in BlueJ geschriebene Programm auf den NXT-Stein zu übertragen. Dies steht allen in BlueJ geschriebenen Klassen zur Verfügung, wie in Abbildung \ref{fig:extension} sichtbar ist.


Mithilfe von BlueJ (oder einer anderen Entwicklungsumgebung) können die SuS unter anderem kontextorientierte Aufgaben lösen. Hierzu gehören zum Beispiel das Anhalten auf einer Linie (vgl. Abb. \ref{fig:Bsp BlueJ Linienfinder}) oder auch den Roboter einer schwarzen Linie folgen zu lassen, was eine der Grundaufgaben im RoboCup Junior Rescue Wettbewerb darstellt (vgl. Abb. \ref{fig:Bsp BlueJ Linienfolger}).



Der Vorteil an der Arbeit mit leJOS besteht darin, dass die SuS direkt mit Java-Code in Berührung kommen. Von Anfang an müssen sie auf syntaktische Korrektheit achten, damit ihr Programm überhaupt auf den NXT Roboter übertragen werden kann. Dabei stellen sich bereits mit wenigen zu lernenden Methoden schnell die ersten Erfolge ein: für das einfache Fahren eines Vierecks müssen die SuS lediglich die  Methoden \texttt{setSpeed()}, \texttt{forward()} und \texttt{backward()} an beiden Motoren, sowie eine Verzögerung mithilfe des Klasse \texttt{Delay} benutzen. 

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/extension.png}
\caption{Die Kontextmenü-Erweiterung der NXJ-Extension}
\label{fig:extension}
\end{figure}



\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/linienfolger_bluej.png} 
\caption{Der Roboter soll einer schwarzen Linie folgen}
\label{fig:Bsp BlueJ Linienfolger}
\end{figure} 

\par \singlespacing
\section{Simulationsumgebungen}
\label{sec:simulationsumgebungen}
\onehalfspacing
Für den virtuellen Umgang mit \textsc{LEGO Mindstorms} Robotern jeder Generation gibt es bereits einige Simulatoren, die frei verfügbar sind.
Zunächst sollte in diesem Zusammenhang eine an der RWTH Aachen genutzte Simulationsumgebung erwähnt werden, in der sich ein Roboter in einer virtuellen 3D-Umgebung bewegen kann (vgl. \cite{rwth}). Diese ist für die Benutzung der Windows-Entwicklungsumgebung \emph{BricxCC} konzipiert, die unter anderem die an \textsc{LEGO} NXT Roboter angepasste Programmiersprache \emph{Not eXactly C (NXC)} (s. \cite{bricxcc}) unterstützt.

Des weiteren existiert \emph{nxcEditor}, eine sowohl mit Windows, als auch mit Linux und \mbox{MacOS} nutzbare Entwicklungsumgebung, die den \emph{nxcSimulator} beinhaltet. Ähnlich wie BricxCC nutzt auch der nxcEditor die Programmiersprache NXC (vgl. \cite{nxceditor}). Programmiert wurde die Entwicklungsumgebung von Frank Knefel und ist in Anlehnung an das vom Fraunhofer IAIS initiierte Lehr-/Lernkonzept \emph{Roberta -- Lernen mit Robotern} konzipiert. Deshalb wird die erwähnte Entwicklungsumgebung inzwischen auch direkt von Roberta als Softwarelösung angeboten wird (vgl. \cite{roberta}).

Abschließend ist noch das umfassende Softwareangebot des Virtuellen Campus Projekts der PHBern zu erwähnen. Dieses umfasst -- neben der Entwicklung von Programmen für \textsc{LEGO Mindstorms} NXT Roboter mithilfe einer eigens für NXT Roboter geschriebenen Klassenbibliothek \emph{NxtJLib} (s. \cite{aegidius:16}) -- die Möglichkeit, das Programm auf verschiedene Weisen auf den NXT-Stein zu übertragen, oder in einem Simulator auszuprobieren (s. \cite{phbern}). 

\singlespacing
\chapter{Anforderungen an die Neu\-im\-ple\-men\-tie\-rung}
\label{chap:anforderungen}
\onehalfspacing
Das folgende Kapitel widmet sich der Untersuchung der in Kapitel \textbf{\ref{sec:einleitung}} vorgestellten ersten Forschungfrage. Hierzu werden zunächst theoretische Überlegungen aus der Literatur präsentiert und diese abschließend mit der Frage nach den Anforderungen aus verschiedenen Perspektiven verknüpft.

\section{Theoretische Verankerung}
\label{sec:theorie_anforderungen}
Nicht nur in der Schule, sondern insbesondere in der Wissenschaft spielt Simulation in der Robotik eine wichtige Rolle \cite[S.13]{hertzberg:12}. Die Anforderungen, die an die wissenschaftlichen Simulationsumgebungen der Robotik gestellt werden, fassen \textsc{Hertzberg, Lingemann} und \textsc{Nüchter} wie folgt zusammen:
\begin{quote}
\begin{itemize}
\item "`Die Umgebung muss hinreichend gut simuliert sein. Die Simulation einer Flughafenterminalhalle muss zum Beispiel 'zufällig' umherlaufende Fluggäste mit Gepäck und Transportkarren umfassen.

\item Der Roboter in seiner Funktionalität muss hinreichend gut simuliert sein. Das betrifft seine Aktionen wie auch seine Sensorik.

\item Relevante Ungenauigkeit technischer Sensoren und Effektoren muss abgebildet werden. Kann zum Beispiel im realen Bild einer Kamera auf dem Roboter ein Orientierungspunkt im Gegenlicht der Fensterfront unsichtbar werden, muss die Simulation diesen Effekt reproduzieren.

\item Die 'Wahrheit' im Simulator ist tabu! Natürlich ist im Simulator der Zustand jedes simulierten Objekts präzise bekannt, einschließlich der Position, Richtung und Geschwindigkeit des Roboters. Die Roboterkontrollsoftware darf hierauf nicht zugreifen, um Information über die Umgebung zu erhalten -- das geht nur über die simulierten Sensoren. (Für die externe Bewertung des Roboterverhaltens ist der Vergleich zwischen der Wahrheit im Simulator und der Information in der Roboterkontrollsoftware aber erlaubt.)

\item Der Simulator sollte für den simulierten Roboter die identische Schnittstelle wie der reale Roboter zwischen Roboterkontrollsoftware einerseits und Robotersensorik und -ak\-tu\-ato\-rik andererseits verwenden; die Roboterkontrollsoftware soll also code-identisch für den realen oder den simulierten Roboter verwendet werden."' \cite[S.14]{hertzberg:12} 
\end{itemize}
\end{quote}

Im Hinblick auf die Entwicklung einer Simulationsumgebung für die Schule sind mehrere Perspektiven von Belang. 
In den folgenden beiden Unterkapiteln werden nun die Anforderungen an die Neuimplementierung eines ersten prototypischen Simulators für \textsc{LEGO Mindstorms} NXT Roboter aus Sicht der Schüler und der Lehrer dargestellt. Zudem wird geklärt, inwiefern die wissenschaftlichen Anforderungen aus dem universitären Bereich, wie oben dargestellt, auch auf die schulische Lehre zutreffen und wie diese gegebenenfalls angepasst werden müssen.
\vspace*{-1ex}
\par \singlespacing
\section{Schülerperspektive}
\label{sec:schüler}
\onehalfspacing

Da es sich bei der Simulationsumgebung zunächst um einen prototypischen Ansatz handelt, der möglicherweise schon ab der fünften, regelmäßig aber ab der siebten Klasse eingesetzt werden soll, steht ein Augenmerk ganz besonders im Fokus: die Einfachheit. Sowohl in der Bedienung des Simulators als auch im Aussehen sollten klare und leicht erkennbare Strukturen vorherrschen. Dieser Designaspekt steht im Zusammenhang mit dem \emph{KISS}-Prinzip. \emph{KISS} ist hierbei die Kurzform für \emph{keep it short and simple} -- den Leitfaden dieses Designansatzes (vgl. \cite[S. 144f.]{moser:12}).

Des Weiteren sollte darauf geachtet werden, dass die SuS für die Programmierung des Roboters und die Benutzung des Simulators eine einheitliche Syntax verwenden können. Hierzu muss die Simulationsumgebung genau die Methoden anbieten, die auch bei dem realen Roboter die Steuerung der Motoren und den Zugriff auf Sensordaten ermöglichen. Dies entspricht dem zweiten Aspekt nach \textsc{Hertz\-berg\-/\-Lin\-ge\-mann\-/Nüch\-ter}, da der simulierte Roboter alle für die Arbeit mit SuS zentralen Funktionen anbieten und sich hinreichend ähnlich wie ein Roboter in der Realwelt verhalten soll. Des weiteren wird hiermit auch der Aspekt der code-identischen Roboterkontrollsoftware erfüllt, da die SuS die Möglichkeit bekommen sollten, das selbe Programm für den Simulator, wie auch für die Steuerung des Roboters selbst zu verwenden.

Ein weiterer Aspekt, den \textsc{Hertz\-berg\-/\-Lin\-ge\-mann\-/Nüch\-ter} beschreiben sind die Parcours. Diese sollten möglichst realitätsgetreu umgesetzt werden. Das heißt, dass Ausschnitte eines bestehenden realen Wettbewerbsparcours genutzt werden könnten, um für die SuS eine möglichst realitätsnahe Testumgebung anzubieten. Der Vorteil realitätsnaher Wettbewerbsumgebungen besteht auch in der Vergleichbarkeit der Ergebnisse. Die SuS lernen gleich zu Beginn einen wichtigen Aspekt bei der Entwicklung von Programmcode für Roboter: nur weil der Roboter im Simulator an einer schwarzen Linie entlangfahren kann, bedeutet dies nicht, dass auch der reale Roboter diese Herausforderung problemlos meistert.

\vspace*{-2ex}
\par \singlespacing
\section{Lehrkraft}
\label{sec:lehrkraft}
\vspace*{-1ex}
\par \onehalfspacing
Für Lehrkräfte ist es erfahrungsgemäß wichtig, dass die Simulationsumgebung alle essentiellen Bausteine der objektorientierten Programmierung im Kontext der \textsc{LEGO} Roboter zur Verfügung stellt. Hierzu gehört das Austesten des Fahrens mithilfe einer Schleife, sowie der verschiedenen Sensoren. Dafür sollte es eine Auswahl an verschiedenen Parcours geben, damit der Fokus bei jedem Parcours auf einer einzigen Sache liegt. Sollen etwa die angebauten Lichtsensoren getestet werden, so bietet es sich an, den Parcours einfach aus einem weißen Hintergrund und einer schwarzen Linie bestehen zu lassen, die entweder senkrecht in der Nähe des Roboters platziert ist, oder als Kurve eine Teilstrecke des realen Labyrinths darstellt.

In diesem Zusammenhang sollte die Möglichkeit gegeben sein, dass Lehrkräfte unter bestimmten Voraussetzungen eigene, an ihren Unterricht angepasste Parcours in die Software einbinden können.

Des weiteren ist es wichtig, dass sich Lehrerinnen und Lehrer schnell in die Simulationsumgebung einarbeiten können, um bei Fragen der SuS sofort Hilfe leisten zu können. 

\par \singlespacing
\section{Erweiterbarkeit aus Entwicklerperspektive} 
\label{sec:erweiterbarkeit}
\onehalfspacing
Nun zu dem Aspekt der Erweiterbarkeit, der für die Entwicklung dieser Simulationsumgebung zentral ist -- insbesondere, da diese für den Einsatz in Schulen konzipiert ist.

Zunächst sollte die Software ausreichend kommentiert werden, damit auch nach Fertigstellung dieser Masterarbeit weitere Module hinzugefügt werden können. Dazu gehören insbesondere einige Arten von Sensoren, die in diesem Prototyp nicht realisiert wurden. Aber auch Modifikationen, die im Rahmen von Veränderungen der leJOS NXJ API stattfinden, müssen berücksichtigt werden können.

Des Weiteren sollte die Software so strukturiert werden, dass gegebenenfalls auch Teile des Quellcodes für zukünftige Implementationen im Rahmen von Erweiterungen oder Anpassungen genutzt werden können. Hierzu sollten Überlegungen zum Einsatz von Paketen und der sinnvollen Trennung zusammengehöriger Klassen getätigt werden.

Leider hat sich während der Entstehung dieser Simulationsumgebung herausgestellt, dass der Verkauf von \textsc{LEGO Mindstorms} NXT Robotern zum 31.\,12.\,15 eingestellt wurde. Dies bedeutet, dass im Hinblick auf die Entwicklung der Robotik in Schulen auch die Möglichkeit, die geschriebene API an die Technologie der \textsc{LEGO Mindstorms} EV3 --  den Nachfolge-Robotern der NXT -- anzupassen, essentiell ist.


\par \singlespacing
\chapter{Entwickelte Software}
\onehalfspacing
\par \singlespacing
\section{Implementationsablauf}
\onehalfspacing
Die Entwicklung des ersten Ansatzes der Simulationsumgebung umfasste mehrere Schritte, sowie einige Vorarbeit. Hierzu gehörten die Erstellung von Skizzen und Mock-Ups, sowie einer Übersicht über die leJOS API. Des Weiteren wurden Integrationsmöglichkeiten in BlueJ erörtert. Die einzelnen Elemente dieser Vorarbeit werden im folgenden Abschnitt kurz zusammengefasst. 
\par \singlespacing
\subsection{Skizzen und Mock-Ups} 
\onehalfspacing
Um eine grafische Struktur festzuhalten und das Ziel der Simulationssoftware zu erfassen wurden zunächst Skizzen angefertigt, die einen groben Überblick über die Benutzeroberfläche geben sollten. Diese enthielten eine beispielhafte Darstellung eines Parcours und eines Roboters, sowie eine Menüzeile am oberen Rand. 

Als nächstes wurde eine spezielle Art von Interaktionsprototypen hergestellt, so genannte \emph{interaktive Mock-Ups}, die eine Subkategorie interaktiver Wireframes darstellen. Interaktive Wireframes sind eine vereinfachte, digitale Darstellung von Benutzerschnittstellen, die einen gewissen Grad an Interaktionslogik umfassen (vgl. \cite[S.162ff.]{moser:12}).

Zur Erstellung der Mock-Ups wurde mit der Software \emph{Axure RP Pro} gearbeitet, mit der sich sowohl einfache als auch komplex verschachtelte Mock-Ups erstellen lassen (s. Abb. \ref{fig:axure}).



\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/axure_mockup.png} 
\caption{Die Bedieneroberfläche von Axure RP Pro}
\label{fig:axure}
\end{figure}

Die Mock-Ups sollten die grundsätzlichen Funktionen der Simulationsumgebung präsentieren. Dabei ist die Darstellung von Szenarien, die sich aus dem Kontext Schule ergeben, von zentraler Bedeutung. Diese Szenarien sind an den Funktionsumfang der NXT Roboter und insbesondere an die Testung der Sensoren gekoppelt und umfassen das Anhalten auf einer schwarzen Linie wie in Abbildung \ref{fig:linienfinder}, das Fahren entlang einer schwarzen Linie wie in Abbildung \ref{fig:linienfolger} und das Finden und Umfahren eines Hindernisses auf der Fahrbahn (s. Abb. \ref{fig:hinderniserkenner}).


\begin{figure}[htb]
\centering
\includegraphics[scale=0.5]{images/mockup_linienfinder.png}
\caption{Anhalten auf einer schwarzen Linie}
\label{fig:linienfinder}
\end{figure}


\begin{figure}[htb]
\centering
\includegraphics[scale=0.5]{images/mockup_linienfolger.png}
\caption{Fahren einer S-Kurve}
\label{fig:linienfolger}
\end{figure}
\vfill

\begin{figure}[htb]
\centering
\includegraphics[scale=0.5]{images/mockup_hinderniserkenner.png}
\caption{Erkennen eines Hindernisses auf der Fahrbahn}
\label{fig:hinderniserkenner}
\end{figure}


\par \singlespacing
\subsection{Weitere Schritte vor Beginn der Implementation}
\onehalfspacing
Nach dem Erstellen der Mock-Ups wurde abgewägt, inwiefern die vorherigen Überlegungen umgesetzt werden konnten. 

Zunächst konnte bestehender Code aus anderen Projekten in dieses Projekt importiert werden. So wurde die leJOS API -- deren Klassen im Paket der Klassenbibliothek frei verfügbar sind -- genutzt, um die Neuimplementation der in \textbf{\ref{sec:API}} beschriebenen Klassen realitätsgetreu miteinander zu verzahnen und die korrekten Beziehungen untereinander zu implementieren.

Des Weiteren wurde die Simulationsoberfläche auf das Anzeigen des Parcours und eines als Dreieck dargestellten Roboters reduziert. Die in den Abbildungen \ref{fig:linienfinder} bis  \ref{fig:hinderniserkenner} erkennbare Menüleiste mit Startbutton am oberen Rand wurde demnach als Erweiterungsmöglichkeit in der Implementation zurückgestellt.

\par \singlespacing
\subsection{Integration in BlueJ}
\label{sec:integration}
\onehalfspacing
Nun zu der Betrachtung der zweiten Forschungsfrage und der derzeit umgesetzten Entscheidung über die Verknüpfung der Entwicklungsumgebung BlueJ mit der Simulationsumgebung.

Die Frage nach einer Integration in BlueJ kann auf vielfältige Art beantwortet werden. Die einfachste und zu diesem Zeitpunkt praktikabelste Lösung ist, die Integration der Simulationsumgebung über einen Import der Klassenbibliothek zu realisieren.

Für die SuS bedeutet dies, dass diese neben der Import-Anweisung für die leJOS-Bibliothek zwei weitere Import-Anweisungen in ihren geschriebenen Code einfügen müssen. Außerdem muss ein Exemplar der Simulator-Klasse erzeugt werden. Solche Anpassungen sind jedoch ein überschaubarer Aufwand für die Lehrkraft sowie die SuS. Diese können auch als "`Schablone"' für die ersten Versuche von der Lehrkraft zur Verfügung gestellt und daher gut im Unterricht genutzt werden.

Nun stellt sich die Frage, wieso überhaupt mit BlueJ gearbeitet werden soll, da es doch ausreichend andere Entwicklungsumgebungen gibt, in die solche Bibliotheken importiert werden können.
Der Vorteil an BlueJ besteht darin, dass diese Entwicklungsumgebung, wie in \textbf{\ref{sec:bluejetc}} beschrieben, eine klar strukturierte und übersichtliche Benutzeroberfläche bietet. Die SuS müssen sich nicht in für ihre Ansprüche überdimensional umfangreiche Programmierumgebungen einarbeiten und können per Mausklick ihren Code per USB-Kabel auf den Roboter übertragen. Diese Übertragung wird von einer speziell für BlueJ entwickelten NXT-Extension realisiert (vgl. \cite{bowes:12}), die eine Erweiterung des Kontextmenüs jeder Klasse zur Verfügung stellt. 


\par \singlespacing
\section{Beschreibung der Software}
\onehalfspacing

Nun zu einer kurzen Beschreibung der Simulationsumgebung, in der zudem Einzelheiten zur Benutzung der Software dargestellt werden.



\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/dialog_szenarien.png} 
\caption{Auswahldialog für den Parcours}
\label{fig:auswahldialog}
\end{figure}

Beginnt man mit dem Programmieren einer Klasse -- welche beispielsweise dafür sorgen soll, dass der NXT Roboter einer Kurve auf dem Boden folgt -- so müssen neben des Imports für die leJOS API zwei weitere Import-Anweisungen für den Simulator eingebunden werden. Diese Klasse wird im Folgenden mit \texttt{linienfolger} bezeichnet.
Zu beachten ist, dass immer entweder der leJOS-Import oder die Simulator-Importe auskommentiert sein müssen, da sonst weder der Simulator noch der reale NXT Roboter weiß, auf welche Bibliothek zugegriffen werden soll.


\begin{figure}[tb]
\centering
\includegraphics[width=\textwidth]{images/simparcours_kurve.png} 
\caption{Eine beispielhafte Darstellung von Parcours und Roboter}
\label{fig:simparcours_kurve}
\end{figure}

Um nun mit dem Simulator zu arbeiten, erzeugt man innerhalb der main-Methode der Klasse \texttt{linienfolger} ein neues Exemplar der Klasse \texttt{Si\-mu\-la\-tor}. Nachdem man \texttt{linienfolger} fehlerfrei kompiliert hat, kann man in BlueJ über einen Rechtsklick die main-Me\-tho\-de ausführen lassen. Dies resultiert darin, dass mit der Erzeugung eines Simulators der Auswahldialog für den Parcours angezeigt wird, wie in Abbildung \ref{fig:auswahldialog} beispielhaft dargestellt ist.
Sobald der Parcours ausgewählt wurde, wird dieser in einem neuen Fenster geöffnet. Nun sehen die SuS den Roboter, der auf dem ausgewählten Parcours fährt (Vgl. Abb.\ref{fig:simparcours_kurve}).

Alternativ kann die Erzeugung des Simulator-Exemplars auch in den Konstruktor ausgelagert werden. Statt einer main-Methode können die SuS in der Konsequenz eine beliebige Methode für die Ausführung ihres Quellcodes verwenden. Nach Erzeugung eines Exemplars \texttt{linienfolger}, bei der die Auswahl des Parcours nun direkt beim Aufruf stattfindet, kann danach an der Klasse die auszuführende Methode über das Kontextmenü ausgewählt werden. Die Simulationsoberfläche ist im Unterschied zum vorigen Ansatz schon vor Auswahl der zu testenden Methode sichtbar. 


\par \singlespacing
\section{Softwarearchitektur}
\onehalfspacing 

Die entwickelte Software besteht -- im derzeitigen Zustand -- aus insgesamt fünfzehn Klassen. Diese sind zur Übersichtlichkeit in Pakete unterteilt, die sich in zwei Kategorien unterscheiden. Zum einen Klassen, welche die API für den Simulator zur Verfügung stellen und die zentralen von leJOS angebotenen Klassen für die NXT Roboter umfassen, zum anderen Klassen, die für die Repräsentation der Simulation auf dem Bildschirm zuständig sind. Erstere sind im Sinne des WAM-Ansatzes als \emph{Services} zu sehen, die Klassen des Simulators als \emph{Werkzeuge} (vgl. \cite[S. 61ff.]{züllighoven:90}, \cite[S. 35f.]{lilienthal:08}). 

Um eine Konsistenz bei den Imports für die SuS zu bewahren, sind die Klassen, welche die simulierten NXT-Teile implementieren, in einem Package mit der Bezeichnung \texttt{nxt} (ähnlich wie bei leJOS) enthalten, die Klassen des Simulators in dem Package \texttt{sim}. 

Zum besseren Verständnis folgt im Weiteren eine kurze Zusammenfassung der in dieser Implementation verwendeten Projektstruktur.


\subsubsection*{Pakete}

Pakete (engl.: packages) in Java fassen Gruppen von Typen zusammen. Ein Beispiel hierfür sind die Standardbibliotheken von Java, die in den Paketen \texttt{java} und \texttt{javax} zu finden sind. Diese enthalten Unterpakete, wie zum Beispiel die Bibliotheken zur Entwicklung grafischer Benutzeroberflächen \emph{Swing} oder auch \emph{AWT} (vgl. \cite[S.265]{ullenboom:12}).
Der Zugriff auf diese Bibliotheks-Klassen erfolgt entweder über eine Pfadangabe bei der Variablendeklaration und -initialisierung oder über eine \texttt{import}-Anweisung. Will man beispielsweise ein Exemplar der Klasse \texttt{Point} aus der Java-Klassenbibliothek \texttt{AWT} erzeugen, so kann dies entweder durch den Befehl\\
\hspace*{2em} \texttt{java.awt.Point Punkt = new java.awt.Point();}\\
statt der "`normalen"' Deklaration und Initialisierung oder aber durch die Anweisung\\ \hspace*{2em} \texttt{import java.awt.Point;}\\
zu Beginn des Quelltexts und dem gewohnten Erzeugen des Objekts durch\\
\hspace*{2em} \texttt{Point Punkt = new Point();}\\
geschehen (vgl. \cite[S.266]{ullenboom:12}).
Möchte man eine ganze Reihe von Klassen eines Pakets importieren, so besteht die Möglichkeit, dies mithilfe eines * am Ende der Import-Deklaration zu tun. Im obigen Beispiel wäre dies\\
\hspace*{2em} \texttt{import java.awt.*;}.\\
Anhand dieser Deklaration ist auch direkt zu erkennen, dass das Paket \texttt{awt} ein Unterpaket des Pakets \texttt{java} ist. Der "`Paketpfad"' bzw. die hierarchische Struktur der Pakete und Unterpakete wird mithilfe von Punkten angegeben (vgl. \cite[S.265ff.]{ullenboom:12}, \cite[S.84ff.]{abts:15}).


\subsection{Externe Frameworks}

\subsubsection*{AWT}

Die Klassenbibliothek AWT (\emph{Abstract Window Toolkit}) stellt die grundlegenden Bausteine zur Erstellung grafischer Benutzeroberflächen zur Verfügung. Die Darstellung von AWT-Komponenten ist an die Darstellungsoptionen des jeweiligen Betriebssystems gekoppelt, wodurch eine Eingrenzung der Möglichkeiten auf diejenigen, die auf alle Betriebssysteme zutreffen, vorhanden ist. Vorteilhaft dabei ist, dass das Erscheinungsbild von Menüleisten und Schaltflächen dem Benutzeroberflächendesign des Betriebssystems entspricht (vgl. \cite[S.279]{abts:15})

Auf einem anderen Konzept bauen die Klassen des Pakets \emph{Swing} auf. 

\subsubsection*{Swing}

Das Paket \texttt{javax.swing} basiert fast vollständig auf Java und ersetzt alle Grundkomponenten des AWT-Frameworks. Im Gegensatz zu AWT wird hier auf die Designkonsistenz zum Betriebssystem verzichtet. Im Gegenzug bekommt man ein einheitliches und plattformunabhängiges \emph{Look \& Feel} (vgl. \cite[S.279]{abts:15}). Dies ist darin begründet, dass die Swing-Komponenten mit "`primitiven Zeichenoperationen gemalt"' werden \cite[S.1018]{ullenboom:12}.


\subsubsection*{ImageIO}

Das Paket \texttt{java.imageio} bietet dem Benutzer Schnittstellen zur Einbindung von Bilddateien in Java an. Hierzu gehört unter anderem das Lesen und Schreiben von Bildern in unterschiedlichen Formaten \cite[S.1280]{ullenboom:12}. Mithilfe der Methode \texttt{ImageIO.read(URL input)} wird ein Bild aus dem übergebenen Verzeichnis oder der URL direkt in das Projekt geladen. 


\par \singlespacing
\subsection{Die Klassen des \texttt{nxt}-Pakets}
\label{sec:API}
\onehalfspacing
In diesem Abschnitt werden nun die durch leJOS vorgegebenen und für die Implementation des Simulators angepassten Klassen vorgestellt. Hierbei handelt es sich um eine kleine Auswahl der essentiell für den Unterricht erforderlichen Klassen, die im Rahmen dieser Arbeit für die Simulationsumgebung angepasst wurden. Die interne Struktur zwischen den einzelnen Klassen ist durch die leJOS API vorgegeben und musste somit realitätsgetreu nachgebildet werden. Die Abbildung \ref{fig:api_uml} stellt diese mithilfe eines UML-Diagramms dar.

\subsubsection{Motoren}
Zunächst wurde die Klasse \texttt{Motor} implementiert. Diese besteht lediglich aus den Feldern \texttt{A}, \texttt{B} und \texttt{C}, die Exemplare der Klasse \texttt{NXTRegulatedMo\-tor} darstellen. Ein NXTRegulatedMotor ist ein an einen Motorport angeschlossener NXT-Motor. Ein solcher Motor wird über den Befehl\\
\hspace*{2em} \texttt{Motor.[port].[Methode]}\\
angesteuert. 

\subsubsection{MotorPort}
Die Klasse \texttt{MotorPort} ist in diesem Projekt eine verkleinerte Version der gleichnamigen Klasse aus der leJOS API. In ihr sind die statischen Variablen \texttt{A, B} und \texttt{C} enthalten, welche die zur Verfügung stehenden MotorPorts am Roboter darstellen. Intern ist jedem Port eine \texttt{id} in Form eines Integer zugeordnet. Über die Methode \texttt{get\-In\-stance(int id)} kann über die private Variable \texttt{id} der öffentliche Port (\texttt{A, B} und \texttt{C}) abgefragt werden.

\subsubsection{NXTRegulatedMotor}
In der Klasse \texttt{NXTRegulatedMotor} befindet sich die auf die Simulationsumgebung angepasste Implementation der NXT-spezifischen Motoren. Den größten Anteil haben hierbei die Bewegungen der beiden Motoren über die Methoden \texttt{for\-ward()} und \texttt{back\-ward()}, sowie die Geschwindigkeitsregulierung über die Methode \texttt{set\-Speed()}. 

Jeder NXTRegulatedMotor ist an einen MotorPort angeschlossen, durch welchen eindeutig zuzuordnen ist, welcher Motor gerade angesprochen werden soll. Dies wird in der Implementation des Simulators durch eine Feldvariable \texttt{{\_}port} gelöst, über die dann abgefragt werden kann, an welchem Motor gerade eine Methode aufgerufen wird. Folglich ist jedes NXT\-Regulated\-Motor\--Objekt ein Exemplar der Klasse NXTRegulatedMotor, welches vom Benutzer einen Port zugeordnet bekommt.

Zudem bekommt jeder Motor eine Feldvariable \texttt{{\_}richtung}, die die Information enthält, ob sich der Motor bewegt (vorwärts oder rückwärts), oder ob er gerade in Ruheposition ist. Dabei entspricht "`vorwärts"' dem Wert 1, "`rückwärts"' dem Wert -1 und mit 0 wird der Ruhezustand bezeichnet.

Die SuS werden ihren geschriebenen Code meist damit beginnen, den beiden Motoren jeweils eine Geschwindigkeit zuzuweisen. Dies geschieht mithilfe der Methode \texttt{setSpeed(int speed)}. Da sich der Roboter auf dem Parcours pixelweise bewegt, wird an dieser Stelle die Geschwindigkeit von den für reale NXT Roboter geeigneten Geschwindigkeiten durch den Faktor 100 geteilt, um eine angemessene Bewegungsgeschwindigkeit auf dem Bildschirm zu sichern.

Danach werden die Motoren in Bewegung versetzt. Hierzu werden die Methoden \texttt{forward()} und \texttt{backward()} benutzt. In der Implementation der Simulationsumgebung wird diese Bewegung als Veränderung der Position und der Ausrichtung der Roboter-Grafik auf der Leinwand realisiert. Je nachdem, welcher Port (\emph{B} entspricht dem linken Motor, \emph{C} dem rechten) angesteuert wird, ruft die Klasse NXTRegulatedMotor die Methode \texttt{aendereBewegung(double winkel, double geschwindigkeit)} -- in Abhängigkeit zur Geschwindigkeit und eines Richtungsmultiplikators -- am Roboter auf. Der Richtungsmultiplikator sorgt hierbei für eine möglichst realitätsnahe Approximation der tatsächlichen Veränderung der Ausrichtung des Roboters. Die Verwendung einer Variablen für diesen Faktor bringt den Vorteil mit sich, dass bei Verbesserungen innerhalb der Bewegungsimplementation der Motoren eine Konsistenz in allen involvierten Methoden sichergestellt ist. Soll beispielsweise die Vorwärtsbewegung der Motoren neu skaliert werden, so kann dies über die Veränderung des Richtungsmultiplikators geschehen und es werden in der Konsequenz alle relevanten Werte in den Methoden gleichzeitig und gleichmäßig verändert. 

Die Herausforderung bei dieser Simulationsumgebung bestand nun darin, dass die Motoren -- auch wenn sie sich schon bewegen -- eine neue Geschwindigkeit weitergegeben bekommen und die zuvor bestimmte Bewegung mit der neuen Geschwindigkeit ausführen. Außerdem sollte ein zweimaliges Aufrufen der Methoden \texttt{forward()} und \texttt{backward()} nicht dazu führen, dass der Roboter sich doppelt so schnell bewegt. Hierzu konnte nun die Information, die in  \texttt{{\_}richtung} enthalten ist, genutzt werden. Mit einfachen if-Abfragen wird zu Beginn des Methodenrumpfs festgestellt, in welcher Bewegung sich der angesprochene Motor gerade befindet. 


\subsubsection{Licht- und Farbsensoren}
Die Lichtsensoren sind zwei von der leJOS API vorgegebene Exemplare der Klasse \texttt{LightSensor}. Diese sind im Simulator derzeit jeweils links und rechts neben der Spitze des Roboter-Dreiecks angebracht (siehe hierzu Abb. \ref{fig:roboter_abstrakt}). Die Berechnung hierzu sehen wie folgt aus:

Für die Bestimmung der Position des rechten Lichtsensors gilt:

Sei $B$ die Breite, $H$ die Höhe und $u$ die Ausrichtung des Roboters. Seien mit $xPos$ und $yPos$ die Koordinaten des Robotermittelpunkts bezeichnet.

Dann gilt
\renewcommand\arraystretch{3}
\begin{align*}
\beta & = \arctan \left( \dfrac{\frac{B}{4}}{\frac{H}{2}} \right)\\
\epsilon & = 90 - (u + \beta)\\
c & = \left( \frac{B}{4} \right) \cdot \arcsin (\beta)\\
x_B & = xPos + \left( c \cdot \sin(\epsilon) \right)\\
y_B & = yPos - \left( c \cdot \cos(\epsilon) \right).
\end{align*}

Für die Berechnung der Position des linken Lichtsensors gilt analog:

Sei $B$ die Breite, $H$ die Höhe und $u$ die Ausrichtung des Roboters. Seien mit $xPos$ und $yPos$ die Koordinaten des Robotermittelpunkts bezeichnet. Dann gilt
\renewcommand\arraystretch{3}
\begin{align*}
\beta & = \arctan \left( \dfrac{\frac{B}{4}}{\frac{H}{2}} \right)\\
\gamma & = u - \beta\\
c & = \left( \frac{B}{4} \right) \cdot \arcsin (\beta)\\
x_A & = xPos - \left( c \cdot \sin(\gamma) \right)\\
y_A & = yPos + \left( c \cdot \cos(\gamma) \right).
\end{align*}

Es folgt also für die beiden Punkte $\mathsf{A}$ und $\mathsf{B}$ in Grafik \ref{fig:roboter_abstrakt}, dass $\mathsf{A} = \left( x_A \vert y_A \right)$ und $\mathsf{B} = \left( x_B \vert y_B \right)$.


Da es sich bei der Implementation um einen Prototyp handelt, existiert noch keine optische Repräsentation der beiden Sensoren am Roboter. 

\begin{figure}[htb]
\centering
\hspace*{-6em}\includegraphics[scale=1.1]{images/lichtsensorgrafik.png} 
\caption{Die Abstraktion des Roboters und der Sensorpositionen}
\label{fig:roboter_abstrakt}
\end{figure}


Die Klasse \texttt{Roboter} enthält die Methoden zur Abfrage der Positionen der Sensoren im Bezug auf die x- und y-Achse. Diese sind mit \texttt{gib\-X\-Licht\-Rechts()}, \texttt{gib\-Y\-Licht\-Rechts()}, \texttt{gib\-X\-Licht\-Links()} und \texttt{gib\-Y\-Licht\-Links()} bezeichnet und werden benötigt, um das Auslesen des Farbwerts des Pixel unter dem jeweiligen Sensor zu ermöglichen. Die eigentliche Abfrage des Helligkeitswertes passiert jedoch am Parcours-Objekt. In der zugehörigen Klasse steht die Methode \texttt{gibLichtmittelwert(int x, int y)} zur Verfügung, die auf das Bilddaten-Array zugreift (s. Abschnitt \textbf{\ref{sec:simpaket}}).

Da die realen Sensoren auch nicht nur einen einzelnen Punkt auf dem Boden, sondern einen Bereich abtasten, berechnet die Methode den Mittelwert aus neun Pixeln um die Position des Lichtsensors. Hierzu wird in der Methode \texttt{gib\-Hellig\-keits\-wert(int x, int y)} der Helligkeitswert jedes einzelnen der neun Pixel aus dem Bilddaten-Array abgefragt und der Mittelwert gebildet. Die Sensoren, die dann mit \texttt{gib\-Licht\-mittel\-wert(int x, int y)} die Helligkeit des ausgewählten Bereichs abfragen, bekommen das genormte Ergebnis (der Wert 0 entspricht schwarz, 100 entspricht weiß) des Mittelwerts ausgegeben.

Die Farbsensoren der NXT Roboter verhalten sich in der Realität ähnlich wie die Lichtsensoren. Somit ist die Implementation der Farbsensoren im Simulator code-identisch und auf eine explizite Beschreibung kann in dieser Ausarbeitung verzichtet werden.

\subsubsection{Ultraschall- und Berührungssensor}
Der Berührungssensor, oder wie von leJOS TouchSensor genannt, ist im Simulator an der vordersten Spitze des Roboter-Objekts platziert. Da Hindernisse im Simulator schwerlich als mehrdimensionale Objekte dargestellt werden können, wird in dieser ersten Version der Simulationsumgebung zunächst mit einer Farbunterscheidung gearbeitet. Dies funktioniert wiederum über den Helligkeitswert der Pixel, die sich gerade unter der Spitze des Roboter-Objekts befindet. Die Position des Sensors ergibt sich dabei in Anhängigkeit zu der Größe des Roboters und seiner Ausrichtung. Sei $B$ die Breite des Roboters und $\alpha$ der Wert aus der Variablen \texttt{{\_}ausrichtung} des Roboters. Weiter entspreche $xPos$ der x-Position und $yPos$ der y-Position des Roboters.

Dann folgt für die Koordinaten $\left( x \vert y \right)$ des Berührungssensors
\begin{align*}
dx & = \left( \sin \alpha \right) \cdot \left( \frac{B}{2} \right)\\
dy & = \left( \cos \alpha \right) \cdot \left( \frac{B}{2} \right)\\
 x & = xPos + dx\\
 y & = yPos - dy.
\end{align*}


Für die Implementation des Ultraschallsensors wird eine Implementation des Hindernisses als Objekt auf dem Parcours benötigt. Dies ist für die Implementation eines ersten Prototyps des Simulators nicht essentiell, da die für SuS relevanten Aufgaben auch mit einem Berührungssensor gelöst werden können. Daher verzichtet dieser Prototyp zunächst auf die Implementation eines Ultraschallsensors.

\subsubsection{Sensorports}
Jeder der eben aufgeführten Sensoren ist an einen so genannten Sensorport angeschlossen. Die Klasse \texttt{SensorPort} enthält Felder, welche die einzelnen Ports darstellen. Ein Exemplar einer Sensoren-Klasse wird bei der Initialisierung stets an einen Sensorport gekoppelt. 
\clearpage


\begin{figure}[H]
\centering
\includegraphics[scale=0.63]{images/uml_api_essenz.png}
\caption[UML-Diagramm der Klassen im \texttt{nxt}-Paket]{UML-Diagramm der wichtigsten von leJOS NXJ vorgegebenen Klassen}
\label{fig:api_uml}
\end{figure}


\par \singlespacing
\subsection{Die Klassen des \texttt{sim}-Pakets}
\label{sec:simpaket}
\onehalfspacing
Nun zu einer Beschreibung der Struktur und Implementation der Klassen, die für die Simulation zuständig sind. Hierzu gehört die grafische Repräsentation des Parcours und des Roboters, der Auswahldialog für den Parcours, sowie die Leinwand, auf welcher der simulierte Roboter fahren soll. Des Weiteren wird die Funktionalität sowie die Interaktion der einzelnen Klassen beschrieben. Eine Gesamtübersicht der wichtigsten Klassen ist in \ref{fig:simulator_uml} abgebildet.

\vspace*{-2ex}
\subsubsection{Simulator}

Um die Simulationsumgebung aufzurufen, erzeugt man ein Exemplar der Klasse \texttt{Si\-mu\-la\-tor}. Der Konstruktor dieser Klasse ist so konzipiert, dass zunächst ein Parcours erzeugt und in diesem Zusammenhang eine Bilddatei mit dem gewünschten Parcours ausgewählt wird.

Als nächstes wird der Roboter über den Konstruktoraufruf\\
\hspace*{2em}\texttt{Roboter(335, 500)}\\
auf den ausgewählten Parcours projiziert.

Die Klasse \texttt{Simulator} ist nicht nur für die Erzeugung der einzelnen Elemente der Simulationsumgebung zuständig, sondern auch für die Verwaltung des Prozessablaufs. Hierzu wird mit dem Aufrufen eines Simulators ein sogenannter \emph{Thread} erzeugt. Im Rumpf des Threads sind wiederum zwei Anweisungen innerhalb einer Endlosschleife zu finden. Zum einen der Befehl\\
\hspace*{2em} \texttt{{\_}roboter.update();}\\
der dafür sorgt, dass der Status des Roboter-Objekts aktualisiert wird, zum anderen eine Verzögerung, ein \emph{Delay}, wodurch die Anweisungen in der Schleife alle Millisekunde neu durchlaufen werden. 


\subsubsection{Bildeinleser}
Die Klasse \texttt{BildEinleser} besitzt keinen Konstruktor, da diese nur als Hilfsklasse bestimmte Methoden zur Verfügung stellen muss. Durch den Aufruf der Methode
\texttt{liesBilddaten()} wird ein JFileChooser erzeugt, mithilfe dessen der Benutzer eine Bilddatei auswählen kann. Die ausgewählte Bilddatei stellt den Parcours dar, auf dem der Roboter simuliert werden soll. Danach wird das Bild so umgewandelt, dass ein Array aus Bildpunkten entsteht. Dies ist für die spätere Arbeit mit Bewegungen und den Einsatz von Sensoren auf dem Parcours hilfreich, da auf jeden Datenpunkt des Parcours per Abruf der zugehörigen Array-Zelle zugegriffen werden kann.


\subsubsection{Parcours}
\label{sec:parcours}
Der Parcours ist die Schnittstelle zwischen Simulator und den Klassen des \texttt{nxt-}Pakets. Sie ist unter anderem dafür zuständig, durch den Aufruf von \texttt{liesBilddaten()} am BildEinleser den Dialog für die Auswahl der Parcours-Grafikdatei zu erzeugen. Zudem ist die Schnittstelle dafür verantwortlich, die Bilddaten an die Leinwand zu übergeben, welche an dieser Stelle erzeugt wird. Hierfür sind die implementierten Methoden \texttt{aktualisiere\-Bildgroes\-se(short[][] bild\-daten)}, \hfill \texttt{er\-zeu\-geLein}-\\\texttt{wand()} und \texttt{zeichneBild()} zuständig. Insbesondere letztere übergibt die Bildpunkte in Form eines short-Arrays an die Leinwand.

Des Weiteren befindet sich in dieser Klasse die Implementation der Abfrage der Helligkeitswerte des Parcours, auf dem sich der Roboter befindet. Diese wurde mithilfe der beiden Methoden \texttt{gib\-Hellig\-keits\-wert(int x, int y)} und \texttt{gib\-Licht\-mittel\-wert(int x, int y)} realisiert. Die genauere Beschreibung der Funktionalität dieser Methoden ist im vorangegangenen Abschnitt über die Licht- und Farbsensoren zu finden.

\subsubsection{Leinwand}
Wie zuvor beschrieben, wird die Leinwand von dem Parcours erzeugt. Die Klasse Leinwand sorgt nun dafür, dass die als Array übergebenen Bildpunkte in einem JFrame -- also einem neuen Fenster -- angezeigt werden.

Des Weiteren bietet die Leinwand eine Methode \texttt{warte()} an, die dafür genutzt wird, dass sich die Objekte auf der Leinwand tatsächlich animiert über den Hintergrund bewegen. Dies geschieht über den Aufruf \texttt{Thread.sleep(millise\-kun\-den)}, der dafür sorgt, dass der Prozess, der sich um das Zeichnen des Roboters kümmert, einige Millisekunden verzögert ausgeführt wird.

\subsubsection{Roboter}
Nun zum Kernstück der Simulationsumgebung, der Klasse \texttt{Roboter}. Diese enthält alle relevanten Informationen des Roboter-Objekts, wie die Position, die Ausrichtung, die Geschwindigkeit -- in Form von Variablen \texttt{{\_}xPos}, \texttt{{\_}yPos}, \texttt{{\_}aus\-rich\-tung},  \texttt{{\_}ge\-schwin\-dig\-keit} -- und das Aussehen. 

Sobald ein neuer Roboter erzeugt wird (\texttt{Roboter(int x, int y)}) wird das Bild des Roboters, welches zur Zeit noch ein einfaches Dreieck ist, eingelesen, auf die Leinwand gezeichnet und auf die übergebene Position gesetzt. Hierbei anzumerken ist, dass die Bilddatei einen imaginären Rahmen besitzt, so dass zwei Feldvariablen zur Positionskorrektur existieren, die für das Zeichnen auf der Leinwand benutzt werden. Hierdurch wird sichergestellt, dass der Roboter auch tatsächlich an der übergebenen Position gezeichnet wird. Beim Konstruktoraufruf übergibt der Benutzer demnach die Koordinaten für den Mittelpunkt des Roboters.

Weiterer Bestandteil der Klasse ist die Methode \texttt{update()}. Diese ist dafür zuständig, dass der Roboter auf der Leinwand Bewegungen ausführen kann. Dies geschieht zunächst über die Veränderung der Ausrichtung des Roboters, wodurch natürlich eine Rotation der optischen Repräsentation des Roboters, und somit des Bildes, nötig ist. Die Methode \texttt{rotate(double Degrees)} erstellt in diesem Zusammenhang eine Kopie der ursprünglichen Robotergrafik, dreht diese um den angegebenen Winkel und ersetzt die bisher bestehende Grafik durch die gedrehte Kopie. Dieses Verfahren sorgt dafür, dass keine Pixelfehler und optischen Verwischungen an der Robotergrafik auf dem Parcours entstehen, da für jede Veränderung eine neue Kopie der Originalgrafik verwendet wird.

Abschließend wird nun der Roboter mithilfe der beiden Methoden \texttt{se\-tzePo\-si\-tion(int x, int y)} und \texttt{zeichnen(int x, int y)} auf der neuen Position auf dem Parcours gezeichnet. In Anlehnung an die leJOS API funktioniert dies über die Veränderung des Winkels und der Geschwindigkeit. Dies ist damit zu begründen, dass von den SuS nur die einzelnen Motoren angesteuert werden können, was dazu führt, dass jeweils nur durch eine Veränderung der Geschwindigkeit eines Motors das Fahren von Kurven möglich ist. Die Berechnung der neuen Position findet dabei wie folgt statt:

Die Feldvariable \texttt{{\_}win\-kel\-Ver\-än\-derung} bekommt durch den Aufruf der Methode \texttt{aen\-de\-re\-Be\-we\-gung(double win\-kel, double ge\-schwin\-dig\-keit)} in der Klasse NXTRegulatedMotor einen neuen Wert zugewiesen. Da dieser im Roboter-Objekt gespeichert ist, kann direkt darauf zugegriffen werden. Der in der Variablen \texttt{{\_}win\-kel\-Ver\-än\-derung} gespeicherte Wert wird nun zunächst auf die Feldvariable \texttt{{\_}ausrichtung} aufaddiert. 

Sei nun $\alpha$ der Wert der Variable \texttt{{\_}ausrichtung} und $v$ die in der Variable \texttt{{\_}ge\-schwin\-dig\-keit} gespeicherte Geschwindigkeit. Des Weiteren entspreche $xPos$ dem Wert von \texttt{{\_}xPos}, sowie $yPos$ dem Wert von \texttt{{\_}yPos}. Dann folgt
\begin{align*}
dx & = \left( \sin \alpha \right) \cdot v\\
dy & = \left( \cos \alpha \right) \cdot v\\
x & = xPos + dx\\
y & = yPos - dy
\end{align*}
und die Zielkoordinaten des Roboters entsprechen dem Punkt $\left( x \vert y \right)$.

Abschließend werden der Roboter und seine Position durch den Aufruf \texttt{zeich\-nen(int x, int y)} an die Leinwand übergeben, die dafür sorgt, dass das neue Gesamtbild im Fenster angezeigt wird.

Im Zusammenspiel mit dem Thread, der in der Klasse Simulator erzeugt wird, führt der regelmäßige Aufruf der Methode \texttt{update()} zu der Bewegungsanimation des Roboters auf der Leinwand.


Des Weiteren enthält die Klasse \texttt{Roboter} eine Vielzahl von sondierenden Methoden, welche die Positionskoordinaten des Roboters, sowie der Lichtsensoren und des Berührungssensors zurückgeben.

Da bei der Implementation jeweils mit der Höhe und Breite, die durch weitere sondierende Methoden (\texttt{getHeight()} und \texttt{getWidth()}) an der Robotergrafik direkt ausgelesen werden können, gearbeitet wurde, besteht die Möglichkeit, die Bilddatei des Roboters auszuwechseln.

\begin{figure}[htb]
\centering
\hspace*{-2.5cm}\includegraphics[scale=0.75]{images/uml_simulator_essenz.png}
\caption[UML-Diagramm der Klassen des Simulators]{UML-Diagramm der essentiellen Klassen für die Simulationsumgebung}
\label{fig:simulator_uml}
\end{figure}


\newpage
\chapter{Fazit und Ausblick}

\onehalfspacing

In dieser Masterarbeit wurde der Protoyp einer Java-Simulations\-um\-ge\-bung für \textsc{LEGO Mindstorms} NXT Roboter entwickelt. Das Ergebnis dieser Entwicklung ist die Möglichkeit, SuS ein Werkzeug zur Überprüfung ihres Quelltextes für die Steuerung eines Roboters an die Hand
zu geben. Die enwickelte Simulationsumgebung umfasst alle für die
Programmierung erster Software mit NXT Robotern essentiellen Klassen sowie deren Methoden und stellt eine Testumgebung für Sensoren und Motorbewegungen zur Verfügung.


\section{Umsetzung der Anforderungen}

Die Simulationsumgebung bietet den SuS die Möglichkeit, mit der von ihnen kennengelernten Syntax (auf Basis der leJOS NXJ API) ihre individuellen Lösungen direkt am Computer auszuprobieren. Hierbei müssen sie sich nicht mit einer neuen, zusätzlichen Benutzeroberfläche vertraut machen, sondern lediglich dre zusätzliche Anweisungen im Quellcode einfügen. Die Steuerung des NXT Roboters und des Roboters in der Simulation ist damit also nahezu code-identisch.

Bezüglich der Realitätstreue der Parcours lässt sich zunächst sagen, dass die beispielhaft im Projekt mit enthaltenen Parcours Ausschnitte eines realen Parcours sein könnten. Dies stellt sicher, dass die SuS ihre Roboter in Testumgebungen fahren lassen können, die einen Bezug zu den Realbedingungen haben.

Außerdem kann jede Lehrkraft mithilfe eines Grafikprogramms weitere Parcours entwerfen und den SuS zur Verfügung stellen. Auch dies gehörte zu den an die Simulationssoftware gestellten Anforderungen.

Zusätzlich zu den Kommentaren im Code, der den Lehrkräften zur Verfügung gestellt wird, ist im Anhang noch eine Kurzanleitung zu finden, die durch die Einbindung der Klassenbibliothek des Simulators in BlueJ führt, sowie Hinweise zur Benutzung enthält. Hierdurch kann ein leichtes Einarbeiten der Lehrkräfte in den Umgang mit der Simulationsumgebung gewährleistet werden. 

Die in \textbf{\ref{chap:anforderungen}} beschriebenen Anforderungen hinsichtlich der Schüler, Lehrer sowie der Erweiterbarkeit konnten demnach in einem guten Maße umgesetzt werden. Die vorgestellte prototypische Simulationsumgebung für \textsc{LEGO Mindstorms} NXT Roboter kann im derzeitigen Zustand bereits den Informatikunterricht an Schulen in einem sinnvollen Maße unterstützen. Sie visualisiert Befehlsabläufe, die von den SuS entwickelt wurden und stellt gleichzeitig den Bezug zwischen Quelltext und Realwelt her. 

\section{Verbesserungen und Erweiterungen}

Da die entwickelte Simulationsumgebung bisher prototypisch ist, sollte sie folglich als nächstes in der Praxis getestet werden. Hierzu kann sie verschiedenen Lehrkräften zur Verfügung gestellt werden, die dann in unterschiedlichen Jahrgangsstufen damit arbeiten können. Dieser Schritt sorgt dafür, dass das Verhalten der Sensoren verfeinert und die Rubustheit des Codes verbessert werden kann.

Damit einher geht auch der Umstand, dass das geforderte Verhalten der Sensoren bisher nur in einem beschränkten Maße getestet wurde. Dies bedeutet,
dass eine hinreichend gute Approximation des Verhaltens der Sensoren beim
Testen mit einem Mustercode erreicht wurde. Eine mögliche Anpassung an die Realbedingungen ist jedoch angezeigt.

Des Weiteren kann die Roboter-Grafik im Simulator, die derzeit zu Testzwecken aus einem Dreieck besteht, durch eine beliebige andere Grafik ausgetauscht werden, um den SuS das Gefühl, dass "`ihr"' Roboter im Simulator gerade die ersten Bewegungen vollführt, zu vermitteln.

Eine weitere Möglichkeit wäre auch, eine Steuerung der Simulation anzubieten, welche ähnlich wie bei \emph{Greenfoot} aufgebaut ist. Konkret würde dies bedeuten, dass der JFrame, in dem der Parcours angezeigt wird, um einen Bereich mit Buttons erweitert würde. Diese wären dann in der Lage, die Simulation zu starten, pausieren und anzuhalten.

Eine umfassendere Änderung wäre das Schreiben einer eigenen BlueJ Extension. Dies würde zwar einen hohen Aufwand bedeuten, jedoch für eine komfortable Integration in die Entwicklungsumgebung sorgen. Hierdurch würde die Möglichkeit entstehen, den Simulator gegebenenfalls direkt am Kontextmenü aufzurufen.

\section{Rückmeldung von Lehrkräften zum Simulator}

Im Rahmen dieser Arbeit wurde der entwickelte Prototyp der Simulationsumgebung aktiv im \textsc{LEGO}-Roboter-Bereich tätigen Lehrkräften vorgestellt. Hierdurch ergaben sich mehrere Anmerkungen und Wünsche, sowie weitere Anforderungen, die für den Einsatz unter Realbedingungen an die Simulationsumgebung gestellt werden könnten. Diese werden im Folgenden vorgestellt und gegebenenfalls um Lösungsansätze für den entwickelten Simulator erweitert.

Auf der Ebene der Benutzerfreundlichkeit wurde der Wunsch geäußert, den Simulator direkt starten zu können. Hierzu solle in einem Dialogfenster die gewünschte Parcours-Grafik, sowie die auszuführende Klasse ausgewählt werden können. Da die Übertragung des von den SuS geschriebenen Programmcodes auf die NXT Roboter ähnlich stattfindet -- nämlich durch die Übertragung der ausgewählten Java-Klasse, und somit der \texttt{.class}-Datei -- könnte hier eine noch deutlichere Verzahnung der Abläufe von der Simulationsumgebung und des realen Roboers stattfinden.

Des Weiteren wurden Anmerkungen zur Robotergrafik gegeben. Zunächst sollte die grafische Repräsentation des Roboter-Objekts auf dem Parcours die Positionen der Sensoren beinhalten. Hierzu wurde der Vorschlag unterbreitet, die drei Standardbauarten der NXT Roboter als auswählbare Grafiken mit fest positionierten Sensoren anzubieten. In der Implementation ließe sich dies realtiv gut über eine Veränderung des Konstruktors der Klasse \texttt{Roboter} lösen. Dieser würde dann, statt eine vorgegebene Image-Datei zu laden, wie die Parcours-Klasse einen Auswahldialog erzeugen, mit dem dann die gewünschte Robotergrafik ausgewählt werden könnte.

Im Hinblick auf eine weiterführende Arbeit mit der Simulationsumgebung spielen die Positionen der Sensoren und anderer Bauteile am NXT Roboter eine bedeutende Rolle. Beispielsweise können minimale Positionsänderungen darüber entscheiden, ob eine Kurve gefahren werden kann. Aufgrund dieser Feinheiten wurde der Wunsch geäußert, eine zusätzliche Bearbeitung des Roboter-Objekts im Simulator zu ermöglichen. Im Idealfall würde der Roboter dann modular aus den relevanten Einzelteilen als Objekte zusammengesetzt, so dass für jeden Motor und jeden Sensor die genaue Position vorgegeben werden könnte, die dann dem Simulator übergeben würde.

Auch die Sensoren der nächsten Generation der \textsc{LEGO} Roboter verhalten sich anders, als die der NXT Roboter. Somit müssten auch auf dieser Ebene in der Simulationsumgebungen Anpassungen stattfinden -- insbesondere bei den Farbsensoren, da diese nun drei verschiedene Modi anbieten.

Ein weiterer programmierspezifischer Aspekt ist, dass die befragten Lehrkräfte ihren SuS beibringen, sich bestimmte Sensordaten auf dem LCD-Display des NXT Roboters anzeigen zu lassen. Die hierzu benötigten Klassen wurden bisher im Simulator nicht umgesetzt. Jedoch könnte das Display als weiteres Fenster während der Simulation hinzugefügt werden, sodass auch die Messdaten der Sensoren auf dem ausgewählten Parcours angezeigt würden. 

Abschließend wurde noch das Problem der Lichtverhältnisse in unterschiedlichen Situationen angeführt. Meist stehen die realen Trainingsparcours und die Wettbewerbparcours in unterschiedlichen Ausrichtungen zu den verschiedenen räumlich bedingten Lichtquellen. So liefert ein weißer Untergrund beispielsweise bei Tageslicht andere Sensordaten als derselbe Untergrund bei künstlichem Lichteinfall. Um auch diese Gegebenheiten möglichst realitätsgetreu simulieren zu können, gäbe es die Möglichkeit, eine Bildbearbeiter-Klasse hinzuzufügen, mit der man dem ausgewählten Parcours in der Simulationsumgebung unterschiedliche Helligkeiten, die durch verschiedene Lichtquellen hervorgerufen werden, übergeben könnte.

Insgesamt lässt sich demnach feststellen, dass die Simulationsumgebung das Potential aufweist, sich durch weitere Verfeinerungen als nützliches Softwareentwicklungstool für \textsc{LEGO Mindstorms} NXT Roboter zu etablieren.

\section{Zusammenfassung}

Die in dieser Masterarbeit entwickelte Java-Simulations\-um\-ge\-bung für \textsc{LEGO Mindstorms} NXT Roboter liefert ein stabiles Tool für den Einstieg in die schriftliche objektorientierte Programmierung anhand von Robotern. Der Simulator ist in der Lage, einfache, auf Basis der NXJ API von leJOS in Java geschriebene Programme auf einem digitalen Parcours auszuführen und den SuS somit eine optische Rückmeldung zu ihrem Code zu geben.

Des Weiteren stellt dieser Simulator eine Basis für Erweiterungen bezüglich UI-spezifischer Anpassungen oder auch für ein Upgrade auf die nächste Generation von \textsc{LEGO Mindstorms} Robotern -- den EV3 -- dar und lässt sich durch den objektorientierten Ansatz in der Programmierung und die Nutzung von Paketen, die in sinnvolle Kategorien unterteilt wurden, relativ einfach umgestalten und erweitern.

Die Weiterentwicklung von Robotern, die im Unterricht eingesetzt werden können, wird auch in Zukunft die informatische Bildung und den Informatikunterricht in Schulen beeinflussen und prägen. Auch die Arbeit mit \textsc{LEGO Mindstorms} Robotern im Kontext der Objektorientierten Programmierung wird sich über viele weitere Generationen von SuS fortsetzen. Der Einsatz der in dieser Masterarbeit entwickelten Simulationsumgebung für derartige Roboter bringt die SuS näher an die realen Verhältinisse wissenschaftlicher Arbeit mit Robotern und kann für die SuS neue Perspektiven öffnen. 

\newpage
\input{bibliography}
\newpage

\KOMAoptions{headsepline=off}
\addchap*{Anhang A}

Die folgende Anleitung soll einen Leitfaden für die Einbindung und Benutzung der Java Simulationsumgebung für \textsc{LEGO Mindstorms} NXT Roboter in BlueJ darstellen.

Zu beachten ist, dass die in den Abbildung sichtbaren Pfade immer abhängig von der persönlichen Ablagestruktur der Dateien ist. Deshalb wird auf eine konkrete Benennung von Pfaden im Zusammenhang mit der Klassenbibliothek sowie dem Ort der Parcours-Grafikdateien verzichtet.



\addsec*{Laden der Klassenbibliothek}

Die Simulationsumgebung wird in Form einer \texttt{.jar}-Datei ausgeliefert (\texttt{simulator.jar}) und sollte an einem nachvollziehbaren Ort im Dateisystem des Computers abgelegt werden. Zur Verwendung muss diese in BlueJ als Klassenbibliothek importiert und geladen werden (s. Abb. \ref{fig:library}).

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/Anleitung_Library.png}
\caption{Die in BlueJ geladenen Klassenbibliotheken}
\label{fig:library}
\end{figure}

\addsec*{Import innerhalb der geschriebenen Klassen}

Um den Simulator nun mit dem in BlueJ geschriebenen Quellcode verwenden zu können, müssen folgende Schritte erfolgen:

Zunächst müssen zwei Import-Anweisungen im Quallcode oberhalb der Klasse eingefügt werden. Gleichzeitig müssen die Imports der leJOS-Bibliotheken auskommentiert werden, wie in Abbildung \ref{fig:import} beispielhaft dargestellt ist.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/Anleitung_Import.png}
\caption{Die Import-Anweisungen im Quellcode}
\label{fig:import}
\end{figure}

\addsec*{Aufrufen des Simulators}

Das Starten des Simulators erfolgt über den Konstrukturaufruf\\
\hspace*{2ex} \texttt{Simulator simulator = new Simulator()};\\
welcher entweder im Konstruktor der geschriebenen Klasse oder aber innerhalb einer Methode platziert werden kann.

Nun erscheint entweder sobald ein neues Exemplar der implementierten Klasse erzeugt wird, oder erst beim Aufruf einer bestimmten Methode der Auswahldialog für die Parcours-Grafik, wie Abbildung \ref{fig:auswahl_szenarien} zeigt. Wird ein Parcours ausgewählt, so startet der Roboter im Parcours-Fenster entweder direkt mit der Simulation oder wartet, bis am erzeugten Exemplar beispielsweise die Methode \texttt{start()} aufgerufen wird.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{images/dialog_szenarien.png}
\caption{Auswahldialog der Szenarien}
\label{fig:auswahl_szenarien}
\end{figure}

\addsec*{Einbindung eigener Grafiken}

Zusätzlich zu den vorgegebenen Szenarien können selbstgestaltete Bilddateien als Parcours-Grafiken eingesetzt werden. Hierbei ist zu beachten, dass die Bilddateien mindestens eine Größe von $740 \times 640$ Pixel aufweisen, damit ausreichend "`Bewegungsfreiheit"' für den Roboter zur Verfügung steht. Außerdem ist der Startpunkt des Roboters genormt. Dieser liegt am Punkt $\left( 335 \vert 450 \right)$.

\addsec*{Weitere Hinweise}

Des Weiteren zu beachten ist der Umstand, dass in der vorliegenden Implementation der Simulationsumgebung der linke Motor des Roboters am Port \texttt{B}, der rechte Motor am Port \texttt{C} angeschlossen ist.\\
Um unnötige Änderungen im Programmcode der SuS zu vermeiden sollte diese Portvergabe auch am NXT-Stein vorliegen.
%\begin{figure}[htb]
%\centering
%\includegraphics[width=\textwidth]{images/Anleitung_Startmethode.png}
%\caption{Aufruf der Methode \texttt{start()} an dem mit dem Simulator verknüpften Exemplar}
%\label{fig:startaufruf}
%\end{figure}

\cleardoublepage
\newpage
\thispagestyle{empty}
\vspace*{\fill}
"Hiermit versichere ich, dass ich die Arbeit selbstständig verfasst und keine anderen als die angegebenen Hilfsmittel – insbesondere keine im Quellenverzeichnis nicht benannten Internet-Quellen – benutzt habe, die Arbeit vorher nicht in einem anderen Prüfungsverfahren eingereicht habe und die eingereichte schriftliche Fassung der auf dem elektronischen Speichermedium entspricht."\\

Hamburg, 8.\,März 2016 \hspace*{\fill} \dots \dots \dots \dots \dots \dots \dots \dots \dots\\
\hspace*{\fill} Pamina Maria Berg \quad $\,$
\end{document}